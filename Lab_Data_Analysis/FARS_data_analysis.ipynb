{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a48f9309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0ceca4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning /content/drive/MyDrive/Lab/Lab_Data_Analysis/...\n",
      "  [+] Found data for Year: 2023\n",
      "  [+] Found data for Year: 2022\n",
      "  [+] Found data for Year: 2020\n",
      "  [+] Found data for Year: 2021\n",
      "Processing 2020...\n",
      "  [?] Checking folder: /content/drive/MyDrive/Lab/Lab_Data_Analysis/2020\n",
      "      Loading: vehicle.csv + VEH_AUX.CSV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3320233892.py:101: DtypeWarning: Columns (56,58,176,178) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_raw = pd.read_csv(path_raw, encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2021...\n",
      "  [?] Checking folder: /content/drive/MyDrive/Lab/Lab_Data_Analysis/2021\n",
      "      Loading: vehicle.csv + VEH_AUX.CSV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3320233892.py:101: DtypeWarning: Columns (14,56,58,176,178) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_raw = pd.read_csv(path_raw, encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2022...\n",
      "  [?] Checking folder: /content/drive/MyDrive/Lab/Lab_Data_Analysis/2022\n",
      "      Loading: vehicle.csv + veh_aux.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3320233892.py:101: DtypeWarning: Columns (14,56,58,176,178) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_raw = pd.read_csv(path_raw, encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2023...\n",
      "  [?] Checking folder: /content/drive/MyDrive/Lab/Lab_Data_Analysis/2023\n",
      "      Loading: vehicle.csv + veh_aux.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3320233892.py:101: DtypeWarning: Columns (53,63,67) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_raw = pd.read_csv(path_raw, encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully imported 235438 total records from 4 years.\n",
      "(235438, 225)\n",
      "\n",
      "Truck Crashes on Curves per Year:\n",
      "YEAR\n",
      "2020    261\n",
      "2021    334\n",
      "2022    294\n",
      "2023    293\n",
      "Name: is_truck_on_curve, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION (Drive Edition)\n",
    "# ==========================================\n",
    "CONFIG = {\n",
    "    # Update this to match your folder structure in Drive\n",
    "    # The '/content/drive/MyDrive/' part is standard for Colab\n",
    "    \"BASE_DIR\": \"/content/drive/MyDrive/Lab/Lab_Data_Analysis/\", \n",
    "\n",
    "    # We will look for these specific filenames inside the folders\n",
    "    \"RAW_FILENAME\": \"vehicle.csv\",\n",
    "    \"AUX_FILENAME\": \"VEH_AUX.csv\",\n",
    "    \n",
    "    # Codes\n",
    "    \"CODES\": {\n",
    "        \"LARGE_TRUCK\": [4], \n",
    "        \"CURVES\": [2, 3, 4] \n",
    "    }\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 2. HELPER: Auto-Detect Years\n",
    "# ==========================================\n",
    "\n",
    "def find_file_insensitive(folder, target_name):\n",
    "    \"\"\"\n",
    "    Scans a folder for a file matching 'target_name', ignoring case.\n",
    "    Example: Finds 'veh_aux.csv' even if you asked for 'VEH_AUX.CSV'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # List all actual files in the directory\n",
    "        actual_files = os.listdir(folder)\n",
    "        \n",
    "        # Check them one by one\n",
    "        for f in actual_files:\n",
    "            if f.lower() == target_name.lower():\n",
    "                return os.path.join(folder, f)\n",
    "                \n",
    "        return None # Not found\n",
    "    except OSError:\n",
    "        return None\n",
    "\n",
    "def find_data_folders():\n",
    "    \"\"\"\n",
    "    Scans the BASE_DIR and finds all folders containing the required files.\n",
    "    Returns a dictionary: { 2021: 'path/to/2021', 2022: 'path/to/2022' }\n",
    "    \"\"\"\n",
    "    valid_years = {}\n",
    "    \n",
    "    # Use glob to find all 'vehicle.csv' files recursively\n",
    "    # The '**' means \"look in every subfolder\"\n",
    "    search_pattern = os.path.join(CONFIG[\"BASE_DIR\"], \"**\", CONFIG[\"RAW_FILENAME\"])\n",
    "    found_files = glob.glob(search_pattern, recursive=True)\n",
    "    \n",
    "    print(f\"Scanning {CONFIG['BASE_DIR']}...\")\n",
    "    \n",
    "    for file_path in found_files:\n",
    "        # Infer the folder path and the year from the file path\n",
    "        folder_path = os.path.dirname(file_path)\n",
    "        \n",
    "        # Try to extract a year from the folder name (e.g., \".../2021/vehicle.csv\")\n",
    "        # We take the folder name immediately containing the file\n",
    "        folder_name = os.path.basename(folder_path)\n",
    "        \n",
    "        if folder_name.isdigit() and len(folder_name) == 4:\n",
    "            year = int(folder_name)\n",
    "            valid_years[year] = folder_path\n",
    "            print(f\"  [+] Found data for Year: {year}\")\n",
    "        else:\n",
    "            print(f\"  [-] Found file in '{folder_name}' but it doesn't look like a year. Skipping.\")\n",
    "            \n",
    "    return valid_years\n",
    "\n",
    "# ==========================================\n",
    "# 3. PROCESSING PIPELINE\n",
    "# ==========================================\n",
    "def load_and_process_year(year, folder_path):\n",
    "    print(f\"  [?] Checking folder: {folder_path}\")\n",
    "    \n",
    "    # Use the smart finder for BOTH files\n",
    "    path_raw = find_file_insensitive(folder_path, CONFIG[\"RAW_FILENAME\"])\n",
    "    path_aux = find_file_insensitive(folder_path, CONFIG[\"AUX_FILENAME\"])\n",
    "    \n",
    "    # 1. Debugging Output (Tells you exactly what is missing)\n",
    "    if not path_raw:\n",
    "        print(f\"  [!] CRITICAL: Could not find raw file '{CONFIG['RAW_FILENAME']}' (checked case-insensitive)\")\n",
    "        return None\n",
    "    if not path_aux:\n",
    "        print(f\"  [!] CRITICAL: Could not find aux file '{CONFIG['AUX_FILENAME']}'\")\n",
    "        # Print what IS there to help you debug\n",
    "        print(f\"      Files actually found in this folder: {os.listdir(folder_path)}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        print(f\"      Loading: {os.path.basename(path_raw)} + {os.path.basename(path_aux)}\")\n",
    "        \n",
    "        # Load (using latin1 for FARS safety)\n",
    "        df_raw = pd.read_csv(path_raw, encoding='latin1')\n",
    "        df_aux = pd.read_csv(path_aux, encoding='latin1')\n",
    "        \n",
    "        # --- Standardize Columns (Renaming Logic) ---\n",
    "        df_raw.columns = [c.upper() for c in df_raw.columns]\n",
    "        df_aux.columns = [c.upper() for c in df_aux.columns]\n",
    "        \n",
    "        if 'VALIGN' in df_raw.columns: df_raw.rename(columns={'VALIGN': 'V_ALIGN'}, inplace=True)\n",
    "        \n",
    "        # --- Merge ---\n",
    "        df_merged = pd.merge(df_raw, df_aux, on=['ST_CASE', 'VEH_NO'], how='inner')\n",
    "        df_merged['YEAR'] = year\n",
    "        \n",
    "        # --- Apply Logic ---\n",
    "        df_merged['is_large_truck'] = df_merged['A_BODY'].isin(CONFIG[\"CODES\"][\"LARGE_TRUCK\"])\n",
    "        df_merged['is_curve'] = df_merged['V_ALIGN'].isin(CONFIG[\"CODES\"][\"CURVES\"])\n",
    "        df_merged['is_truck_on_curve'] = df_merged['is_large_truck'] & df_merged['is_curve']\n",
    "        \n",
    "        return df_merged\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  [!] Error processing {year}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ==========================================\n",
    "# 4. MAIN EXECUTION\n",
    "# ==========================================\n",
    "all_data = []\n",
    "detected_years = find_data_folders()\n",
    "\n",
    "if not detected_years:\n",
    "    print(\"No valid data folders found! Check your BASE_DIR path.\")\n",
    "else:\n",
    "    # Sort years to process in order\n",
    "    for year in sorted(detected_years.keys()):\n",
    "        print(f\"Processing {year}...\")\n",
    "        df_year = load_and_process_year(year, detected_years[year])\n",
    "        \n",
    "        if df_year is not None:\n",
    "            all_data.append(df_year)\n",
    "\n",
    "    # Combine\n",
    "    if all_data:\n",
    "        final_df = pd.concat(all_data, ignore_index=True)\n",
    "        print(f\"\\nSuccessfully imported {len(final_df)} total records from {len(all_data)} years.\")\n",
    "        print(final_df.shape)\n",
    "        \n",
    "\n",
    "        # Quick Check\n",
    "        summary = final_df.groupby('YEAR')['is_truck_on_curve'].sum()\n",
    "        print(\"\\nTruck Crashes on Curves per Year:\")\n",
    "        print(summary)\n",
    "    else:\n",
    "        print(\"Processing complete, but no data was generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
